name: Deploy URL Shortener

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write         # REQUIRED for GitHub OIDC -> AWS
  contents: read          # allows checkout

env:
  AWS_REGION: us-east-1                         # keep consistent with your setup
  ARTIFACT_BUCKET: ddemo-artifacts-676206911400-us-east-1  #Will later want account id to be a secret.  Probably good to add for security section
  ARTIFACT_KEY: releases/current.zip

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install app + dev deps
        run: |
          python -m pip install --upgrade pip
          pip install -r app/requirements.txt
          pip install -r requirements-dev.txt

      - name: Lint (flake8)
        run: |
          flake8 .

      - name: Ensure repo on PYTHONPATH
        run: echo "PYTHONPATH=$PYTHONPATH:$GITHUB_WORKSPACE" >> $GITHUB_ENV

      - name: Run tests (pytest)
        run: |
          mkdir -p reports
          pytest -q --junitxml=reports/junit.xml

      # FOR DATADOG STEP
      - name: Upload JUnit to Datadog
        if: always()
        env:
          DATADOG_API_KEY: ${{ secrets.DD_API_KEY }}
          DATADOG_SITE: ${{ secrets.DD_SITE }}
        run: |
          npm -g install @datadog/datadog-ci
          datadog-ci junit upload \
            --service ddemo-urlshort \
            --env demo \
            reports/junit.xml

  build-and-deploy:
    needs: [lint-and-test] #Adding lint/test dependency
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Write build info (UTC timestamp + commit)
        run: |
          ts_utc=$(date -u +"%Y-%m-%dT%H:%M:%SZ")   # ISO-8601 UTC
          sha="${GITHUB_SHA:-local}"
          mkdir -p app
          cat > app/.buildinfo.json <<EOF
          {
            "deployed_at_utc": "${ts_utc}",
            "git_sha": "${sha}"
          }
          EOF

      # Package the app
      - name: Zip /app folder as release artifact
        run: |
          mkdir -p build
          (cd app && zip -r ../build/app.zip .)
          ls -lh build

      # Configure AWS credentials via OIDC (no long-lived keys)
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::676206911400:role/GitHubActionsDeployRole  # <-- replace ACCOUNT_ID and role name if different
          aws-region: ${{ env.AWS_REGION }}

      # Upload the artifact to S3
      - name: Upload artifact to S3
        run: |
          aws s3 cp build/app.zip "s3://${ARTIFACT_BUCKET}/${ARTIFACT_KEY}" --acl private
      
      # Terraform to provision/update infra in ./infra
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init/Plan/Apply
        working-directory: infra
        run: |
          terraform init -input=false
          terraform plan -input=false \
            -var="region=${{ env.AWS_REGION }}" \
            -var="artifact_bucket=${{ env.ARTIFACT_BUCKET }}" \
            -var="artifact_key=${{ env.ARTIFACT_KEY }}"
          terraform apply -auto-approve -input=false \
            -var="region=${{ env.AWS_REGION }}" \
            -var="artifact_bucket=${{ env.ARTIFACT_BUCKET }}" \
            -var="artifact_key=${{ env.ARTIFACT_KEY }}"

      - name: Capture Terraform outputs (fresh IDs)
        id: tf_out
        working-directory: infra
        run: |
            echo "INSTANCE_ID=$(terraform output -raw instance_id)" >> "$GITHUB_OUTPUT"
            echo "PUBLIC_DNS=$(terraform output -raw public_dns)"   >> "$GITHUB_OUTPUT"
        
      - name: Wait for EC2 to be running
        run: |
            aws ec2 wait instance-running --instance-ids "${{ steps.tf_out.outputs.INSTANCE_ID }}"
    
      - name: Wait for EC2 status checks to pass
        run: |
            aws ec2 wait instance-status-ok --instance-ids "${{ steps.tf_out.outputs.INSTANCE_ID }}"

      # Read instance ID & public DNS from Terraform outputs
      - name: Read Terraform outputs
        id: tf
        working-directory: infra
        run: |
          echo "INSTANCE_ID=$(terraform output -raw instance_id)" >> $GITHUB_OUTPUT
          echo "PUBLIC_DNS=$(terraform output -raw public_dns)" >> $GITHUB_OUTPUT

      # Trigger deploy script on the instance via SSM Run Command
      - name: Trigger deploy via SSM
        run: |
          aws ssm send-command \
            --instance-ids "${{ steps.tf.outputs.INSTANCE_ID }}" \
            --document-name "AWS-RunShellScript" \
            --comment "DDemo deploy" \
            --parameters commands=["/usr/local/bin/deploy.sh s3://${{ env.ARTIFACT_BUCKET }}/${{ env.ARTIFACT_KEY }} && sudo systemctl restart urlshort.service"] \
            --output text

      # (Optional but nice) Wait for app to be healthy
      - name: Wait for /healthz
        run: |
          set -e
          URL="http://${{ steps.tf.outputs.PUBLIC_DNS }}/healthz"
          echo "Waiting for $URL ..."
          for i in {1..30}; do
            if curl -sSf "$URL" > /dev/null; then
              echo "OK!"
              exit 0
            fi
            echo "not ready yet... ($i)"
            sleep 5
          done
          echo "App did not become healthy in time."
          exit 1

      - name: Echo site URL
        run: echo "Site == http://${{ steps.tf.outputs.PUBLIC_DNS }}"

  observe-with-datadog:
    needs: [build-and-deploy]   # or whatever your deploy job id is
    runs-on: ubuntu-latest
    env:
      DATADOG_API_KEY: ${{ secrets.DD_API_KEY }}
      DATADOG_SITE: ${{ secrets.DD_SITE }}
      DD_ENV: ${{ secrets.DD_ENV || 'demo' }}
      DD_SERVICE: ${{ secrets.DD_SERVICE || 'ddemo-urlshort' }}
    steps:
      - name: Mark start time
        id: t0
        run: echo "START_TS=$(date +%s)" >> $GITHUB_OUTPUT

      - name: Emit pipeline success metric
        if: success()
        run: |
          set -euo pipefail
          TS=$(date +%s)
          HOST="${{ secrets.DD_SITE }}"
          # Normalize site (allow us5.datadog.com) -> us5.datadoghq.com
          if [[ "$HOST" == *"datadog.com" ]] && [[ "$HOST" != *"datadoghq.com" ]]; then
            HOST="${HOST/datadog.com/datadoghq.com}"
          fi
          API_HOST="api.${HOST}"

          # v2 series payload (omit type to avoid enum parsing issues)
          PAYLOAD=$(cat <<'JSON'
          {
            "series": [
              {
                "metric": "ddemo.pipeline.status",
                "points": [
                  { "timestamp": __TS__, "value": 1 }
                ],
                "tags": [
                  "workflow:${{ github.workflow }}",
                  "job:${{ github.job }}",
                  "sha:${{ github.sha }}",
                  "branch:${{ github.ref_name }}",
                  "service:ddemo-urlshort",
                  "env:demo"
                ]
              }
            ]
          }
          JSON
          )
          PAYLOAD=${PAYLOAD/__TS__/$TS}

          curl -sS -X POST "https://${API_HOST}/api/v2/series" \
            -H "Content-Type: application/json" \
            -H "DD-API-KEY: ${{ secrets.DD_API_KEY }}" \
            -d "$PAYLOAD"

      - name: Emit pipeline duration metric (seconds)
        if: always()
        run: |
          set -euo pipefail
          END=$(date +%s)
          START=${{ steps.t0.outputs.START_TS }}
          DURATION=$(( END - START ))

          HOST="${{ secrets.DD_SITE }}"
          if [[ "$HOST" == *"datadog.com" ]] && [[ "$HOST" != *"datadoghq.com" ]]; then
            HOST="${HOST/datadog.com/datadoghq.com}"
          fi
          API_HOST="api.${HOST}"

          PAYLOAD=$(cat <<'JSON'
          {
            "series": [
              {
                "metric": "ddemo.pipeline.deploy_duration_s",
                "points": [
                  { "timestamp": __TS__, "value": __VAL__ }
                ],
                "tags": [
                  "workflow:${{ github.workflow }}",
                  "job:${{ github.job }}",
                  "sha:${{ github.sha }}",
                  "branch:${{ github.ref_name }}",
                  "service:ddemo-urlshort",
                  "env:demo"
                ]
              }
            ]
          }
          JSON
          )
          PAYLOAD=${PAYLOAD/__TS__/$END}
          PAYLOAD=${PAYLOAD/__VAL__/$DURATION}

          curl -sS -X POST "https://${API_HOST}/api/v2/series" \
            -H "Content-Type: application/json" \
            -H "DD-API-KEY: ${{ secrets.DD_API_KEY }}" \
            -d "$PAYLOAD"

      - name: Create Datadog event
        env:
          DD_SITE: ${{ secrets.DD_SITE }}
          DD_API_KEY: ${{ secrets.DD_API_KEY }}
          DD_APP_KEY: ${{ secrets.DD_APP_KEY }}
        run: |
          set -euo pipefail
          if [[ -z "${DD_APP_KEY:-}" ]]; then
            echo "DD_APP_KEY secret is required for Events v2" >&2
            exit 1
          fi
          HOST="$DD_SITE"
          if [[ "$HOST" == *"datadog.com" ]] && [[ "$HOST" != *"datadoghq.com" ]]; then
            HOST="${HOST/datadog.com/datadoghq.com}"
          fi
          API_HOST="api.${HOST}"

          TITLE="Deploy succeeded"
          TEXT="Workflow ${{ github.workflow }} run #${{ github.run_number }} deployed ${{ github.sha }}"
          TAGS="workflow:${{ github.workflow }},branch:${{ github.ref_name }},service:${{ env.DD_SERVICE }},env:${{ env.DD_ENV }}"

          EVENT_PAYLOAD=$(cat <<JSON
          {
            "title": "${TITLE}",
            "text": "${TEXT}",
            "tags": [$(printf '"%s",' ${TAGS//,/ } | sed 's/,$//')],
            "source": "github_actions"
          }
          JSON
          )

          curl -sS -X POST "https://${API_HOST}/api/v2/events" \
            -H "Content-Type: application/json" \
            -H "DD-API-KEY: ${DD_API_KEY}" \
            -H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
            -d "${EVENT_PAYLOAD}"